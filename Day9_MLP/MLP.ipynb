{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "MLP",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN_pVd5cU2QQ"
      },
      "source": [
        "# 과제: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
        "\n",
        "\n",
        "## Loading MNIST training data\n",
        "\n",
        "출처: 18기 DS 김승하님"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwZNV5MFU2QQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scaling(image data는 min-max scaling 주로 사용)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDU8J2xRU2QQ"
      },
      "source": [
        "## Training Data\n",
        "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVvXmjQSU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d42e23a-36a5-4ab1-b5e7-5efc4cb4b9d3"
      },
      "source": [
        "x_train.shape "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VTAAYKSU2QQ"
      },
      "source": [
        "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
        "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq36yUX8U2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d469b1-97b1-4b90-c352-1eded1ad53eb"
      },
      "source": [
        "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQLH9iXU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4910b500-90ae-4e01-ac43-766647f88eb7"
      },
      "source": [
        "# Hint: x_train[0].reshape()\n",
        "plt.imshow(x_train[0].reshape(28,28)).set_cmap('Greys')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZXzr-AU2QR"
      },
      "source": [
        "## Training Labels\n",
        "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
        "마찬가지로, 60000개의 label이 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-JVvQcJU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35467618-8494-463a-cb7b-6e7f56a2d389"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgAkJK6yU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1605e28-869c-491f-d367-1bc24e547a58"
      },
      "source": [
        "# show MNIST label for above data\n",
        "y_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSshVnt2U2QS"
      },
      "source": [
        "# parameters for model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation function"
      ],
      "metadata": {
        "id": "uIr5UClxsGgn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coUZ53nKU2QS"
      },
      "source": [
        "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ],
      "metadata": {
        "id": "T1qEhOErsJNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = [\"sparse_categorical_crossentropy\",\n",
        "             \"categorical_crossentropy\", \n",
        "             \"binary_crossentropy\"]"
      ],
      "metadata": {
        "id": "RJne2xHXsJvJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ],
      "metadata": {
        "id": "FfIoSNPEsNM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]"
      ],
      "metadata": {
        "id": "sNdc7cUHsPYo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Innitialization"
      ],
      "metadata": {
        "id": "zlHWduVYj3Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
        "                    tf.keras.initializers.RandomUniform(), \n",
        "                    tf.keras.initializers.he_normal(), \n",
        "                    tf.keras.initializers.he_uniform(), \n",
        "                    tf.keras.initializers.GlorotUniform(),\n",
        "                    tf.keras.initializers.GlorotNormal()]"
      ],
      "metadata": {
        "id": "EE3WQDPasUV2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model trials"
      ],
      "metadata": {
        "id": "mTqLRgctsZOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# regularizer\n",
        "regularizer = tf.keras.regularizers.l1(1e-3)\n",
        "regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          activity_regularizer=regularizer)\n",
        "])\n",
        "\n",
        "# weight initialization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          kernel_initializer=initializer_list[0])\n",
        "])"
      ],
      "metadata": {
        "id": "gImTz7WIvq5G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From Scratch\n",
        "oh_y_train = [[0]*10  for i in range(len(y_train))]\n",
        "for idx, oh_vec in enumerate(oh_y_train):\n",
        "  oh_vec[y_train[idx]] = 1\n",
        "oh_y_test = [[0]*10  for i in range(len(y_test))]\n",
        "for idx, oh_vec in enumerate(oh_y_test):\n",
        "  oh_vec[y_test[idx]] = 1\n",
        "oh_y_train = np.array(oh_y_train)\n",
        "oh_y_test = np.array(oh_y_test)\n",
        "\n",
        "#Using API\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_train_oh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBs3tP9tdP1v",
        "outputId": "916de495-6584-4da1-c29f-1e058cc8a7fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for loss in loss_list:\n",
        "  for optimizer in optimizer_list:\n",
        "    if loss == \"categorical_crossentropy\":\n",
        "      mod_y_train = oh_y_train\n",
        "      mod_y_test = oh_y_test\n",
        "    else:\n",
        "      mod_y_train = y_train\n",
        "      mod_y_test = y_test\n",
        "    # dropout\n",
        "    dropout_rate = 0.3\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(512, input_dim=784, activation = \"sigmoid\", kernel_initializer=initializer_list[0]),\n",
        "        tf.keras.layers.Dense(10, activation = \"sigmoid\"),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    # sometime model diverges : needs regularization and weight innitialization\n",
        "    temp_model = model\n",
        "    temp_model.compile(loss = loss, optimizer = optimizer, metrics = [\"accuracy\"] )\n",
        "    temp_model.fit(x_train, mod_y_train)\n",
        "    test_loss, test_acc = temp_model.evaluate(x_test,mod_y_test, verbose=2)\n",
        "    print(loss, optimizer)\n",
        "    print('Accuracy:', test_acc, '\\nLoss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiKhUOKDa-jw",
        "outputId": "cb6d4a00-dbbf-417d-b80d-e874ec754770"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.0044 - accuracy: 0.2055\n",
            "313/313 - 1s - loss: 1.5327 - accuracy: 0.1618 - 598ms/epoch - 2ms/step\n",
            "sparse_categorical_crossentropy sgd\n",
            "Accuracy: 0.16179999709129333 \n",
            "Loss: 1.5326632261276245\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.7186 - accuracy: 0.5212\n",
            "313/313 - 1s - loss: 0.3351 - accuracy: 0.9175 - 600ms/epoch - 2ms/step\n",
            "sparse_categorical_crossentropy adam\n",
            "Accuracy: 0.9175000190734863 \n",
            "Loss: 0.33512234687805176\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.1194 - accuracy: 0.6365\n",
            "313/313 - 1s - loss: 0.2800 - accuracy: 0.9317 - 605ms/epoch - 2ms/step\n",
            "sparse_categorical_crossentropy rmsprop\n",
            "Accuracy: 0.9316999912261963 \n",
            "Loss: 0.279960960149765\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.3392 - accuracy: 0.1793\n",
            "313/313 - 1s - loss: 2.2918 - accuracy: 0.1009 - 579ms/epoch - 2ms/step\n",
            "sparse_categorical_crossentropy adagrad\n",
            "Accuracy: 0.10090000182390213 \n",
            "Loss: 2.2918334007263184\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8689 - accuracy: 0.4126\n",
            "313/313 - 1s - loss: 1.1766 - accuracy: 0.7871 - 576ms/epoch - 2ms/step\n",
            "categorical_crossentropy sgd\n",
            "Accuracy: 0.7871000170707703 \n",
            "Loss: 1.1766072511672974\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 5.0345 - accuracy: 0.6409\n",
            "313/313 - 1s - loss: 0.2304 - accuracy: 0.9314 - 561ms/epoch - 2ms/step\n",
            "categorical_crossentropy adam\n",
            "Accuracy: 0.9314000010490417 \n",
            "Loss: 0.2304457575082779\n",
            "1875/1875 [==============================] - 20s 2ms/step - loss: nan - accuracy: 0.2766\n",
            "313/313 - 1s - loss: nan - accuracy: 0.0980 - 553ms/epoch - 2ms/step\n",
            "categorical_crossentropy rmsprop\n",
            "Accuracy: 0.09799999743700027 \n",
            "Loss: nan\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.2768\n",
            "313/313 - 1s - loss: nan - accuracy: 0.0980 - 582ms/epoch - 2ms/step\n",
            "categorical_crossentropy adagrad\n",
            "Accuracy: 0.09799999743700027 \n",
            "Loss: nan\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: -16.3197 - accuracy: 0.0997\n",
            "313/313 - 1s - loss: -7.0361e+00 - accuracy: 0.0981 - 597ms/epoch - 2ms/step\n",
            "binary_crossentropy sgd\n",
            "Accuracy: 0.09809999912977219 \n",
            "Loss: -7.036069393157959\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: -16.3163 - accuracy: 0.1075\n",
            "313/313 - 1s - loss: -1.3985e+01 - accuracy: 0.1061 - 572ms/epoch - 2ms/step\n",
            "binary_crossentropy adam\n",
            "Accuracy: 0.10610000044107437 \n",
            "Loss: -13.984556198120117\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: -16.3829 - accuracy: 0.1239\n",
            "313/313 - 1s - loss: -1.8462e+01 - accuracy: 0.1305 - 587ms/epoch - 2ms/step\n",
            "binary_crossentropy rmsprop\n",
            "Accuracy: 0.13050000369548798 \n",
            "Loss: -18.462255477905273\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: -16.1006 - accuracy: 0.0795\n",
            "313/313 - 1s - loss: -4.4335e+00 - accuracy: 0.0668 - 583ms/epoch - 2ms/step\n",
            "binary_crossentropy adagrad\n",
            "Accuracy: 0.06679999828338623 \n",
            "Loss: -4.433529376983643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model"
      ],
      "metadata": {
        "id": "dbxes3uJzcpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.3\n",
        "regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1024, input_dim=784, activation = \"sigmoid\", activity_regularizer = regularizer, kernel_initializer = initializer_list[4]),\n",
        "    tf.keras.layers.Dense(512, activation= \"sigmoid\", activity_regularizer = regularizer),\n",
        "    tf.keras.layers.Dense(28, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dropout(dropout_rate),\n",
        "    tf.keras.layers.Dense(10, activation = \"sigmoid\"),\n",
        "])\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"] )\n",
        "model.summary()\n",
        "model.fit(x_train, oh_y_train)\n",
        "test_loss, test_acc = model.evaluate(x_test, oh_y_test, verbose=2)\n",
        "print('Accuracy:', test_acc, '\\nLoss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PszC2EUVubDe",
        "outputId": "4d121f22-618c-4bd2-b9a0-b50ee7a415de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_116 (Dense)           (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 28)                14364     \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 10)                290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,343,294\n",
            "Trainable params: 1,343,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6114 - accuracy: 0.8650\n",
            "313/313 - 1s - loss: 0.2109 - accuracy: 0.9575 - 813ms/epoch - 3ms/step\n",
            "Accuracy: 0.9574999809265137 \n",
            "Loss: 0.21093787252902985\n"
          ]
        }
      ]
    }
  ]
}